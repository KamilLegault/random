# -*- coding: utf-8 -*-
"""model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/butlerbt/SegmentingBuildings/blob/colab/model.ipynb

# Modeling of building footprints

### This notebook trains a UNET model on image segmentation based on already public datasets.

The general overview is:
1. load files
2. create the databunch in the fast ai format
3. Find the ideal learning rate
4. train pretrained model 
5. unfreeze the head and refine the model

Mount the google drive
"""

from google.colab import drive 
drive.mount('/content/drive/')

# install fastai
!curl https://course.fast.ai/setup/colab | bash

#import fastai
from fastai.vision import *
from fastai.callbacks import *
from fastai.utils.collect_env import *

"""### Train model"""

#Load the training data
import glob
import pandas as pd
ims = glob.glob('data/processed/images/*.png')
df = pd.DataFrame({
    'img_path':ims,
    'mask_path':[im.replace('images', 'masks').replace('.png', '_mask.png') for im in ims],
    'valid':False
})

# Mark validation data
holdout_grids = ['validation_']
valid_idx = [i for i,o in enumerate(df['img_path']) if any(c in str(o) for c in holdout_grids)]
df['valid'].iloc[valid_idx]=True

#Create the data Fast.ai dataset
def my_open(self, fn): return open_mask(fn, div=True)
SegmentationLabelList.open = my_open

src = (SegmentationItemList.from_df(path='', df=df, cols='img_path')
       .split_from_df(col='valid')
       .label_from_df(cols='mask_path', classes=["building", "not"]))

data = (src.transform(get_transforms(), size=256, tfm_y=True)
        .databunch(bs=32)
        .normalize(imagenet_stats))

data.show_batch(2, figsize=(10,7))

for idx in range(10,15):
    print(data.valid_ds.items[idx])
    fig, (ax1,ax2) = plt.subplots(1,2, figsize=(10,5))
    data.valid_ds.x[idx].show(ax=ax1)
    ax2.imshow(image2np(data.valid_ds.y[idx].data*255))
    plt.show()

#load a unet resnet34 pretrained model 
learn = unet_learner(data, models.resnet34, metrics=dice, model_dir='models/')

lr = 1e-2
learn.fit_one_cycle(10, max_lr=lr 
                    )

lr = 1e-4
learn.fit_one_cycle(10, max_lr=lr 
                    )

lr = 1e-5
learn.fit_one_cycle(10, max_lr=lr 
                    )

lr = 3e-3
learn.fit_one_cycle(10, max_lr=lr 
                    )

learn.model.eval()
outputs,labels,losses = learn.get_preds(ds_type=DatasetType.Valid,n_batch=3,with_loss=True)

losses_reshaped = torch.mean(losses.view(outputs.shape[0],-1), dim=1)
sorted_idx = torch.argsort(losses_reshaped,descending=True)

learn.show_results()

"""## Fine tune model"""

learn.load('stage-1');
learn.unfreeze()

lr = 3e-3
lrs = slice(lr/400,lr/4)
learn.fit_one_cycle(30, lrs, pct_start=0.8)

learn.recorder.plot_losses()

learn.model.eval()
outputs,labels,losses = learn.get_preds(ds_type=DatasetType.Valid,n_batch=6,with_loss=True)
losses_reshaped = torch.mean(losses.view(outputs.shape[0],-1), dim=1)
sorted_idx = torch.argsort(losses_reshaped,descending=True)

for i in sorted_idx[:5]:

    print(f'{data.valid_ds.items[i]}')
    print(f'loss: {losses_reshaped[i].mean()}')

    fig, (ax1, ax2) = plt.subplots(1,2, figsize=(10,5))
    data.valid_ds.x[i].show(ax=ax1)
    ax1.imshow(outputs[i,1], alpha = .6)
    data.valid_ds.x[i].show(ax=ax2)
    ax2.imshow(labels[i,0], alpha = .4)

    ax1.set_title('Prediction')
    ax2.set_title('Ground Truth')
    
    plt.show()

"""### Train model on 1028 images"""

import glob
import pandas as pd
ims = glob.glob('data/processed/images/*.png')
df_1 = pd.DataFrame({
    'img_path':ims,
    'mask_path':[im.replace('images', 'masks').replace('.png', '_mask.png') for im in ims],
    'valid':False
})

ims = glob.glob('data/processed/images/*.png')
df_2 = pd.DataFrame({
    'img_path':ims,
    'mask_path':[im.replace('images', 'masks').replace('.png', '_mask.png') for im in ims],
    'valid':False
})
df_2.head()

df_3 = pd.concat([df, df_2], axis = 0)

holdout_grids = ['validation_']
valid_idx = [i for i,o in enumerate(df_3['img_path']) if any(c in str(o) for c in holdout_grids)]

df_3['valid'].iloc[valid_idx]=True

def my_open(self, fn): return open_mask(fn, div=True)
SegmentationLabelList.open = my_open

src = (SegmentationItemList.from_df(path='', df=df_3, cols='img_path')
       .split_from_df(col='valid')
       .label_from_df(cols='mask_path', classes=["building", "not"]))

data = (src.transform(get_transforms(), size=512, tfm_y=True)
        .databunch(bs=bs)
        .normalize(imagenet_stats))

data.show_batch(2, figsize=(10,7))

learn = unet_learner(data, models.resnet34, metrics=dice, model_dir='models/')

lr = 3e-3
learn.fit_one_cycle(10, slice(lr), pct_start=0.8)

learn.show_results()

learn.unfreeze()
lrs = slice(1e-6, lr/10)

learn.fit_one_cycle(10, lrs)

learn.export("models/stage-2-big.pkl")

inference_learner = load_learner(path='models/', file='stage-2-big.pkl')

"""### Train model on 128 zoom 19

"""

import glob
import pandas as pd
ims = glob.glob('data/processed/images/*.png')
df = pd.DataFrame({
    'img_path':ims,
    'mask_path':[im.replace('images', 'masks').replace('.png', '_mask.png') for im in ims],
    'valid':False
})
df.head()

holdout_grids = ['validation_']
valid_idx = [i for i,o in enumerate(df['img_path']) if any(c in str(o) for c in holdout_grids)]
print(len(valid_idx))
df['valid'].iloc[valid_idx]=True

tfms = get_transforms(flip_vert=True, max_warp=0.1, max_rotate=20, max_zoom=2, max_lighting=0.3)

def my_open(self, fn): return open_mask(fn, div=True)
SegmentationLabelList.open = my_open

src = (SegmentationItemList.from_df(path='', df=df, cols='img_path')
       .split_from_df(col='valid')
       .label_from_df(cols='mask_path', classes=["building", "not"]))

data = (src.transform(tfms, size=128, tfm_y=True)
        .databunch(bs=32)
        .normalize(imagenet_stats))

"""## Now Train model on 256 zoom 19

"""

#google drive times out and prenvents the glob from operating 80% of the time.. just keep running the cell till it collects 27000 files 

import glob
import pandas as pd
ims = glob.glob('data/processed/images/*.png')
df = pd.DataFrame({
    'img_path':ims,
    'mask_path':[im.replace('images', 'masks').replace('.png', '_mask.png') for im in ims],
    'valid':False
})

holdout_grids = ['validation_']
valid_idx = [i for i,o in enumerate(df['img_path']) if any(c in str(o) for c in holdout_grids)]
print(len(valid_idx))
df['valid'].iloc[valid_idx]=True

tfms = get_transforms(flip_vert=True, max_warp=0.1, max_rotate=20, max_zoom=2, max_lighting=0.3)

def my_open(self, fn): return open_mask(fn, div=True)
SegmentationLabelList.open = my_open

src = (SegmentationItemList.from_df(path='', df=df, cols='img_path')
       .split_from_df(col='valid')
       .label_from_df(cols='mask_path', classes=["building", "not"]))

data = (src.transform(tfms, size=256, tfm_y=True)
        .databunch(bs=32)
        .normalize(imagenet_stats))

data.show_batch()

learn = unet_learner(data, 
                     models.resnet34, metrics=dice,
                     model_dir='models')

learn.unfreeze()
lr=1e-3
lrs = slice(1e-6,lr/10)
learn.fit_one_cycle(3, lrs)

learner = learn
from skimage import io
import time

def get_pred(learner, tile):
#     pdb.set_trace()

    t_img = Image(pil2tensor(tile[:,:,:3],np.float32).div_(255))
    outputs = learner.predict(t_img)
    im = image2np(outputs[2].sigmoid())
    im = (im*255).astype('uint8')
    return im

urls = [
  'https://tiles.openaerialmap.org/5b1009f22b6a08001185f24a/0/5b1009f22b6a08001185f24b/19/319454/270706.png',
  'https://tiles.openaerialmap.org/5b1e6fd42b6a08001185f7bf/0/5b1e6fd42b6a08001185f7c0/20/569034/537093.png',
  'https://tiles.openaerialmap.org/5beaaba463f9420005ef8db0/0/5beaaba463f9420005ef8db1/19/313479/283111.png',
  'https://tiles.openaerialmap.org/5d050c3673de290005853a91/0/5d050c3673de290005853a92/18/203079/117283.png',
  'https://tiles.openaerialmap.org/5c88ff77225fc20007ab4e26/0/5c88ff77225fc20007ab4e27/21/1035771/1013136.png',
  'https://tiles.openaerialmap.org/5d30bac2e757aa0005951652/0/5d30bac2e757aa0005951653/19/136700/197574.png'
]

inference_learner = learn
for url in urls:
  t1 = time.time()
  test_tile = io.imread(url)
  result = get_pred(inference_learner, test_tile)
  t2 = time.time()
  
  print(url)
  print(f'GPU inference took {t2-t1:.2f} secs')
  fig, (ax1, ax2) = plt.subplots(1,2, figsize=(10,5))
  ax1.imshow(test_tile)
  ax2.imshow(result[:,:,1])
  ax1.axis('off')
  ax2.axis('off')
  plt.show()